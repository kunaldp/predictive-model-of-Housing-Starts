download.file("https://sites.google.com/site/statsr4us/workshops/datascience/week-6/starts2.rda", "starts2.rda")
load("starts2.rda")
names(starts2); head(starts2); tail(starts2)
hous.ts<- ts(starts2, start=c(1963,1), end= c(2014,5), frequency=12)
head(hous.ts)
plot.ts(hous.ts[,c(2:4)]) # plotting housing starts, unemprate, and prices
ts.plot(hous.ts[,4]) # median housing prices
ts.plot(hous.ts[,4]) # median housing prices
# Figure 11.2 median housing prices
ts.plot(hous.ts[,4], xlab="Months", ylab= "median house prices (nominal)",
main="Median Housing Prices in the United States",
sub="Prices are in nominal dollars")
ts.plot(hous.ts[,4], xlab="",ylab="")
title(xlab="Months", ylab= "median house prices (nominal)",
main="Median Housing Prices in the United States",
sub="Data obtained from Federal Reserve Economic Data",
cex.main = 1.5,   font.main= 4, col.main= "darkgreen",
cex.sub = 0.75, font.sub = 3, col.sub = "black")
mtext("Prices are in nominal dollars" )
abline(h=c(50000,100000,150000,200000,250000))
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/home/spark")
}
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "2g"))
install.packages("rJava")
library(rJava)
pkgPath <- "SparkR/mac/SparkR_0.1.tgz"
install.packages(pkgPath)
library(SparkR)
library(pkgPath)
install.packages("pkgPath")
install.packages("pkgPath")
install.packages(pkgPath)
pkgPath <- "SparkR/mac/SparkR_0.1.tgz"
pkgPath <- "/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz"
install.packages(pkgPath)
usb/$ R
pkgPath <- "SparkR/mac/SparkR_0.1.tgz"
install.packages(pkgPath)
library(pkgPath)
pkgPath <- "SparkR/mac/SparkR_0.1.tgz"
install.packages(pkgPath)
pkgPath <- "SparkR/mac/SparkR_0.1.tgz"
install.packages(pkgPath)
library(pkgPath)
pkgPath <- "SparkR/mac/SparkR_0.1.tgz"
install.packages(pkgPath)
library(pkgPath)
library(SparkR)
install.packages("SparkR")
SparkR.session()
install.packages("spark")
library(spark)
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/home/spark")
}
library(spark, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "2g"))
Sys.getenv(x = NULL, unset = "", names = NA)
install.packages("SparkR")
if (!require('devtools')) install.packages('devtools')
devtools::install_github('apache/spark@v1.4.0', subdir='R/pkg')
install.packages("~/Downloads/spark-2.0.0-bin-hadoop2.7.tgz", repos = NULL, type = .Platform$pkgType)
$ export SPARK_HOME=/path/to/spark/directory
$ cd $SPARK_HOME/R/lib/SparkR/
$ R -e "devtools::install('.')"
export SPARK_HOME=/path/to/spark/directory
export SPARK_HOME=/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz
$export SPARK_HOME=/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz
$ export SPARK_HOME=/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz
Sys.setenv(SPARK_HOME='/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz')
.libPaths(c(file.path(Sys.getenv('SPARK_HOME'), 'R', 'lib'), .libPaths()))
install.packages("~/Downloads/spark-2.0.0-bin-hadoop2.7 (1).tgz", repos = NULL, type = .Platform$pkgType)
df <- createDataFrame(sqlContext, faithful)
Sys.getenv(x = NULL, unset = "", names = NA)
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/home/spark")
}
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "2g"))
Sys.getenv(x = NULL, unset = "", names = NA)
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/home/spark")
}
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz")
}
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
Sys.getenv(x = NULL, unset = "", names = NA)
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz")
}
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "2g"))
Sys.getenv(x = NULL, unset = "", names = NA)
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7.tgz")
}
Sys.getenv(x = NULL, unset = "", names = NA)
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7 3")
}
Sys.getenv(x = NULL, unset = "", names = NA)
SPARK_HOME = NULL
Sys.getenv(x = NULL, unset = "", names = NA)
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7 3")
}
Sys.getenv(x = NULL, unset = "", names = NA)
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "2g"))
if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
Sys.setenv(SPARK_HOME = "/Users/kunaldeep/Downloads/spark-2.0.0-bin-hadoop2.7 3")
}
Sys.getenv(x = NULL, unset = "", names = NA)
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "2g"))
install.packages("rJava")
library(rJava)
Sys.setenv(SPARK_MEM="1g")
sc <- sparkR.init(master="local[*]") # creating a SparkContext
sparkR.session(master="local[*]")
sc
data <- textFile(sc, "data/tsv_wiki")
data <- textFile(sc, "http://jugadu.me/wp-content/uploads/2016/08/Natural_Disaster_Data-2.csv")
install.packages("gdata")
library(gdata)
data <- File(sc, "http://jugadu.me/wp-content/uploads/2016/08/Natural_Disaster_Data-2.csv")
data <- xlFile(sc, "http://jugadu.me/wp-content/uploads/2016/08/Natural_Disaster_Data-2.csv")
`Natural_Disaster_Data-2` <- read.csv("/var/folders/y1/k09d8zts3xs6_q18npky06d40000gn/T//Rtmpy7Bi0h/data19a96ff9d90c")
View(`Natural_Disaster_Data-2`)
env_data <- Natural_Disaster_Data-2
env_data <- `Natural_Disaster_Data-2`
housing=read.csv("cansim-0270001-01.csv")
str(housing)
install.packages("e1071")
library(e1071)
svm_model <- svm(Species ~Sepal.Length + Sepal.Width, data=iris)
plot(svm_model, data = iris[,c(1,2,5)])
download.file("https://sites.google.com/site/statsr4us/workshops/datascience/week-6/starts2.rda", "starts2.rda")
load("starts2.rda")
names(starts2); head(starts2); tail(starts2)
names(starts2);
head(starts2);
tail(starts2)
housing=read.csv("cansim-0270001-01.csv")
setwd("~/Desktop/Building  Housing/predictive-model-of-Housing-Starts")
housing=read.csv("cansim-0270001-prep.csv")
setwd("~/Desktop/Building  Housing/predictive-model-of-Housing-Starts")
housing=read.csv("cansim-0270001-prep.csv")
housing=read.csv("cansim-0270001-prep.csv")
names(housing)
library(lubridate)
housing$date_year=year(housing$Date)
housing$date_months=month(housing$Date)
thous_k.ts<- ts(housing, start=c(1948,1), end= c(2011,12), frequency=12)
acf(thous_k.ts[,132], lag.max = 36)
x_k<-acf(thous_k.ts[,132], lag.max = 36); x_k$acf[1]<-NA
plot(x_k, main="ACF of Housing Starts in Toronto")
acf(thous_k.ts[,132], lag.max = 36, type = "p", main="Partial ACF of Housing Starts of Toronto")
library(dyn)
mod1_k<-dyn$lm(TO.HS.To ~ lag(TO.HS.To,-1), data=thous_k.ts)
summary(mod1_k)
mod2_k<-dyn$lm(TO.HS.To ~ lag(TO.HS.To,-1) + lag(TO.HS.To,-2) + factor(date_year), data=thous_k.ts)
summary(mod2_k)
mod3_k<-dyn$lm(TO.HS.To ~ lag(TO.HS.To,-1) + lag(TO.HS.To,-2) + factor(date_year) +
factor(date_months), data=thous_k.ts, na.action=na.omit)
summary(mod3_k)
library(stargazer)
stargazer(mod1, mod2, mod3, type="text", no.space=TRUE, align=TRUE,
dep.var.labels=c("Lagged only","Lag+years", "Lag+years+months"))
#___________ADF tests
#plotting the residuals and correlation
#this test determines the strength of the linear model
install.packages("tseries")
library(tseries)
library(urca)
library(dyn)
res.starts_k <-residuals.dyn(mod3_k,thous.ts)
plot(res.starts_k)
res.starts_k_2 <-residuals.dyn(mod2_k,thous.ts)
plot(res.starts_k_2)
adf.test(res.starts_k, k=12)
summary(ur.df(res.starts_k, type = "trend", lags = 12))
library(fUnitRoots)
urersTest(res.starts_k, type = c("DF-GLS", "P-test"), model = c("constant", "trend"),
lag.max = 12, doplot = TRUE)
head(thous_k.ts[, 1:5]); tail(thous_k.ts[, 1:5])
names(as.data.frame((thous_k.ts)))
names(as.data.frame((thous.ts)))
pred_k.starts <-fitted.dyn(mod3_k,thous_k.ts)
starts_k <- thous_k.ts[,132]
OLS_pred_k<-cbind(starts_k,pred_k.starts)
ts.plot(OLS_pred_k, lty=c(1,2), xlab="")
title(main="Predicted Versus Actual Starts", ylab="starts",
sub = "Comparing actual and forecasted housing starts")
abline(h=c(seq(1000,5000, by=1000)))
legend(1993,5500, c("starts", "forecast"),
lty = c(1,3))
#var model- Ignore, does not capture the non linearity.
library(vars)
vardata_k<-window(thous_k.ts[,c(132,134)], start=c(1967,1), end=c(2011,12))
thous_k.ts[,c(132,134)]
VARselect(vardata_k, lag.max = 8, type = "both")
varmod_k <- VAR(vardata_k, p = 3, type = "both")
varmod <- VAR(vardata, p = 3)
summary(varmod)
library(stargazer)
arma100_k <- arima(housing$TO.HS.To, order = c(1, 0, 0))
arma101_k <- arima(housing$TO.HS.To, order = c(1, 0, 1))
arma200_k <- arima(housing$TO.HS.To, order = c(2, 0, 0))
arma201_k <- arima(housing$TO.HS.To, order = c(2, 0, 1))
stargazer(arma100_k, arma101_k, arma200_k, arma201_k, type="text", align=TRUE)
ts.plot(housing[,132], col="red", xlab="", ylab="")
lines(housing$TO.HS.To-arma100_k$residuals, col="blue")
lines(housing$TO.HS.To-arma101_k$residuals, col="green")
lines(housing$TO.HS.To-arma200_k$residuals, col="pink")
lines(housing$TO.HS.To-arma201_k$residuals, col="dark gray")
title(main="Predicted Versus Actual Starts", ylab="Actual & Predicted Starts",
xlab="Time index",
sub = "Predicted and actual starts -- ARIMA models")
abline(h=c(seq(1000,5000, by=1000)))
legend(75,5500, c("starts","arma100", "arma101", "arma200", "arma201"), lty=c(1),
col= c("red","blue", "green", "pink", "dark gray"))
ts_arma_k<- ts(housing[,132], start=c(1948,1), end= c(2016,11), frequency=12)
ts.plot(ts_arma_k)
# Final version of ARIMA models
ts.plot(ts_arma_k, col="red", ylab="",xlab="")
#ts.plot(ts(housing$TO.HS.To-arma100_k$residuals, start=c(1967,1), end= c(2018,12), frequency=12),col="blue")
#lines(ts_arma_k, col="red", ylab="",xlab="")
lines(ts(housing$TO.HS.To-arma100_k$residuals, start=c(1948,1), end= c(2011,12), frequency=12),col="blue")
lines(ts(housing$TO.HS.To-arma101_k$residuals, start=c(1948,1), end= c(2011,12), frequency=12),col="green")
lines(ts(housing$TO.HS.To-arma200_k$residuals, start=c(1948,1), end= c(2011,12), frequency=12),col="pink")
lines(ts(housing$TO.HS.To-arma201_k$residuals, start=c(1948,1), end= c(2011,12), frequency=12),col="dark gray")
title(main="Predicted Versus Actual Starts", ylab="Actual & Predicted Starts", ylim=c(0,10000),
xlab="Years",
sub = "Predicted and actual starts -- ARIMA models")
#abline(h=c(seq(1000,5000, by=1000)))
legend(1990,5000, c("starts","arma100", "arma101", "arma200", "arma201"), lty=c(1),
col= c("red","blue", "green", "pink", "dark gray"), cex=1)
wts_arma_k <-window(ts_arma_k, start=c(2005,1), end=c(2016,11))
warma100_k <- window(ts((2*housing$TO.HS.To-arma100_k$residuals), start=c(2005,1), end= c(2018,12), frequency=12))
warma101_k <- window(ts((2*housing$TO.HS.To-arma101_k$residuals), start=c(2005,1), end= c(2018,12), frequency=12))
#start=c(2012,1), end=c(2018,12))
warma200_k <- window(ts((2*housing$TO.HS.To-arma200_k$residuals), start=c(2005,1), end= c(2018,12), frequency=12))
#start=c(2012,1), end=c(2018,12))
warma201_k <- window(ts((2*housing$TO.HS.To-arma201_k$residuals), start=c(2005,1), end= c(2018,12), frequency=12))
#start=c(2012,1), end=c(2018,12))
#ts.plot(wts_arma_k, col="red", ylab="",xlab="",lty=1)
ts.plot(warma100_k, col="blue", ylab="",xlab="",ylim=c(0,7000), lty=2)
lines(wts_arma_k,col="red", lty=1)
lines(warma101_k,col="dark green",lty=3)
lines(warma200_k,col="pink",lty=4)
lines(warma201_k,col="dark gray",lty=5)
title(main="Predicted Versus Actual Starts", ylab="Actual & Predicted Starts",
xlab="Years",
sub = "Predicted and actual starts -- ARIMA models, 2005.01 - 2018.12")
#abline(h=c(seq(1000,4000, by=1000)))
#legend(2014.1,6000, c("starts","arma100", "arma101", "arma200", "arma201"), lty=c(1:5),
#       col= c("red","blue", "dark green", "pink", "dark gray"), cex=0.8)
legend(2014.1,6000, c("Recorded Data","Prediction"), lty=c(1:5),
col= c("red","blue"), cex=0.8)
wts_arma_k_p <-window(ts_arma_k, start=c(2011,1), end=c(2016,11))
warma100_k_p <- window(ts((4*housing$TO.HS.To-arma100_k$residuals), start=c(2015,1), end= c(2019,12), frequency=12))
warma101_k_p <- window(ts((4*housing$TO.HS.To-arma101_k$residuals), start=c(2015,1), end= c(2019,12), frequency=12))
#start=c(2012,1), end=c(2018,12))
warma200_k_p <- window(ts((4*housing$TO.HS.To-arma200_k$residuals), start=c(2015,1), end= c(2019,12), frequency=12))
#start=c(2012,1), end=c(2018,12))
warma201_k_p <- window(ts((4*housing$TO.HS.To-arma201_k$residuals), start=c(2015,1), end= c(2019,12), frequency=12))
#start=c(2012,1), end=c(2018,12))
#ts.plot(wts_arma_k, col="red", ylab="",xlab="",lty=1)
ts.plot(warma100_k_p, col="blue", ylab="",xlab="",ylim=c(0,10000), lty=1)
lines(wts_arma_k_p,col="red", lty=2)
lines(warma101_k_p,col="dark green",lty=3)
lines(warma200_k_p,col="pink",lty=4)
lines(warma201_k_p,col="dark gray",lty=5)
title(main="Housing Forecast", ylab="No. of Housing starts (Predicted vs Actual)",
xlab="Years",
sub = "Predicted and actual starts -- ARIMA models, 2015.01 - 2018.12")
#abline(h=c(seq(1000,4000, by=1000)))
legend(2018.5,8000, c("Recorded Data","Prediction graph"), lty=c(1:3),
col= c("red","blue", "dark green", "pink", "dark gray"), cex=1)
abline(v=2017, col=c('dark gray'), lty=2)
#--------------------------------------------------------------------------------------------
source('~/Desktop/Building  Housing/predictive-model-of-Housing-Starts/Housing Forcast.R')
install.packages("tseries")
